"""
Generate power consumption and performance traces from traces binary files

Author      : Juan Encinas <juan.encinas@upm.es>
Date        : October 2022
Description : Functions on this file read, process, filter and format the power
              consumption and performance traces that are stored in the CON.bin
              and SIG.bin files generated by the Monitor
"""

import numpy as np
from scipy.signal import butter, lfilter
from copy import deepcopy
from multimethod import multimethod

from .find_elements import get_closest_element_below


@multimethod
def read_power_data(path: str, board: str):
    """ Reads the data from the power consumption file
    """

    power_data_raw = []

    # Read binary file as uint32
    power_data_raw = np.fromfile(path, dtype='uint32')

    # Get elapsed time in cycles (last data of the file)
    power_data_adquisition_duration = power_data_raw[-1]

    # print("\npower_data_adquisition_duration: ",\
    # power_data_adquisition_duration)

    if board == "ZCU":
        # This is a dual power measurement, we have to divide the data
        # Don't care about last element since is indicates the elapsed time
        # in cycles
        top_power_data = power_data_raw[:-1:2]
        bottom_power_data = power_data_raw[1:-1:2]

        # Generate acquisition time (it is a periodic acquisition)
        power_time = np.linspace(0,
                                 power_data_adquisition_duration,
                                 len(top_power_data),
                                 dtype=int)

        # There is no conversion back to list because the process_power_data
        # function uses nparrays. Returns np arrays
        return top_power_data, bottom_power_data, power_time

    elif board == "PYNQ":

        power_data = power_data_raw[:-1]

        # Generate acquisition time (it is a periodic acquisition)
        power_time = np.linspace(0,
                                 power_data_adquisition_duration,
                                 len(power_data),
                                 dtype=int)

        # There is no conversion back to list because the process_power_data
        # function uses nparrays. Returns np arrays
        return power_data, power_time


@multimethod
def read_power_data(buffer: memoryview, board: str):
    """ Reads the data from the power consumption file
    """

    power_data_raw = []

    # Read binary file as uint32
    power_data_raw = np.frombuffer(buffer, dtype='uint32')

    # Get elapsed time in cycles (last data of the file)
    power_data_adquisition_duration = power_data_raw[-1]

    # print("\npower_data_adquisition_duration: ",\
    # power_data_adquisition_duration)

    if board == "ZCU":
        # This is a dual power measurement, we have to divide the data
        # Don't care about last element since is indicates the elapsed time
        # in cycles
        top_power_data = power_data_raw[:-1:2]
        bottom_power_data = power_data_raw[1:-1:2]

        # Generate acquisition time (it is a periodic acquisition)
        power_time = np.linspace(0,
                                 power_data_adquisition_duration,
                                 len(top_power_data),
                                 dtype=int)

        # There is no conversion back to list because the process_power_data
        # function uses nparrays. Returns np arrays
        return top_power_data, bottom_power_data, power_time

    elif board == "PYNQ":

        power_data = power_data_raw[:-1]

        # Generate acquisition time (it is a periodic acquisition)
        power_time = np.linspace(0,
                                 power_data_adquisition_duration,
                                 len(power_data),
                                 dtype=int)

        # There is no conversion back to list because the process_power_data
        # function uses nparrays. Returns np arrays
        return power_data, power_time


def butter_lowpass(cutoff, fs, order=5):
    """ Create Butterworth lowpass filter """
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    return b, a


def butter_lowpass_filter(data, cutoff, fs, order=5):
    """ Apply Butterworth lowpass filter """
    b, a = butter_lowpass(cutoff, fs, order=order)
    y = lfilter(b, a, data)
    return y


def filter_power_data(power_data, enabled, order, fs, cutoff):
    """ Apply Butterworth lowpass filtering if desired, otherwise is just a
        bridge
    """

    if enabled is True:
        power_data_filtered = butter_lowpass_filter(power_data,
                                                    cutoff,
                                                    fs,
                                                    order)

        return power_data_filtered

    return power_data


def process_power_values_zcu(power_data_a,
                                power_data_b,
                                power_time,
                                system_freq_MHz,
                                rshunt_index_a,
                                rshunt_index_b):

    """ Conver from binary value to actual watts """

    # Power conversion formula
    adc_reference_voltage = 2.5
    adc_gain = 100
    adc_resolution = 12
    vdd = 0.85

    rshunt_a = float(5 / 1000) if rshunt_index_a == 0 else float(2 / 1000)
    rshunt_b = float(5 / 1000) if rshunt_index_b == 0 else float(2 / 1000)

    #                              Vref * READ_VALUE
    # P = VDD * Ishunt = VDD * --------------------------- = \
    #                           2^resolucion * K * Rshunt
    #
    #   CONVERSION_FACTOR * READ_VALUE
    #

    power_conversion_factor_a = \
        (vdd * adc_reference_voltage) / \
        (2**adc_resolution * adc_gain * rshunt_a)

    power_conversion_factor_b = \
        (vdd * adc_reference_voltage) / \
        (2**adc_resolution * adc_gain * rshunt_b)

    # Convert time from cycles to ms
    x_values = (power_time / (system_freq_MHz * 1000))
    # Apply the conversion factor to the power values
    y_values_a = (power_data_a * power_conversion_factor_a)
    y_values_b = (power_data_b * power_conversion_factor_b)
    # Returns np arrays
    return [x_values, y_values_a, x_values, y_values_b]


def process_power_values_pynq(power_data,
                                 power_time,
                                 system_freq_MHz):

    """ Conver from binary value to actual watts """

    # Power conversion formula
    adc_reference_voltage = 2.5
    adc_gain = 50.4
    adc_resolution = 12
    vdd = 5.0

    rshunt = float(100 / 1000)

    #                              Vref * READ_VALUE
    # P = VDD * Ishunt = VDD * --------------------------- = \
    #                           2^resolucion * K * Rshunt
    #
    #   CONVERSION_FACTOR * READ_VALUE
    #

    power_conversion_factor = \
        (vdd * adc_reference_voltage) / \
        (2**adc_resolution * adc_gain * rshunt)

    # Convert time from cycles to ms
    x_values = (power_time / (system_freq_MHz * 1000))
    # Apply the conversion factor to the power values
    y_values = (power_data * power_conversion_factor)
    # Returns np arrays
    return [x_values, y_values]


@multimethod
def read_traces_data(path):
    """ Reads the data from the traces file """

    # Read binary file as uint32 and reshape to a list of list of 2 elements
    # (value,counter)
    events_data_raw = np.fromfile(path, dtype='uint32').reshape(-1, 2)

    # Return np arrays
    return events_data_raw


@multimethod
def read_traces_data(buffer: memoryview):
    """ Reads the data from the traces file """

    # Read binary file as uint32 and reshape to a list of list of 2 elements
    # (value,counter)
    events_data_raw = np.frombuffer(buffer, dtype='uint32').reshape(-1, 2)

    # Return np arrays
    return events_data_raw


def process_traces_data(events_data_raw, pos):
    """ Rebuild the events data """

    # Input format
    # (time in cycles, events for every signal in binary)
    # (num_signals-1 downto 0)

    # Copy the raw events to a np array
    # (we don't want to modify the input values)
    events = np.copy(events_data_raw)

    # Modify de column #1 to keep only the bit corresponding to POS
    events[:, 1] = (events[:, 1] & 2**pos) >> pos

    # Remember rows and columns indexes are zero-based
    #
    # We want keep the first event (real value actually) and every event for
    # the signal #POS
    #
    # To do so we will keep only the rows for which the #POS bit in the signal
    # value (column #1) is set to one (meaning there is a event).
    # As well as the first row.
    #
    # We have already remove every bit except #POS bit in the signals value
    # (column #1) so we can assume the value of column #1 is the value of
    # the bit #POS
    #
    # Then, we create a mask with true for each row (starting from row #1)
    # for which the column #1 value is 1
    # Then we insert a True at the beginning to always keep row #0
    #
    aux_mask = events[1:, 1] == 1
    conditional_mask = np.concatenate(([True], aux_mask))

    # Apply the mask for the row, keeping all columns for the selected rows
    events = events[conditional_mask, :]

    # We need to convert from events to actual values
    #
    # To do so, we compute the XOR of the actual value and previous value for
    # every element in column #1 (except for row #0 which stores the actual
    # value, not an event)
    #
    # example:
    # a) prev_value = 0 | actual_value = 1 -> means that before the value
    #                                         was 0 and an event has just
    #                                         occured, so we set the actual
    #                                         value to 1 (as it is)
    # b) prev_value = 1 | actual_value = 1 -> means that before the value
    #                                         was 1 and an event has just
    #                                         occured, so we set the actual
    #                                         value to 0 (toggle)
    # c) prev_value = X | actual_value = 0 -> means that there has been no
    #                                         event, so we set actual value
    #                                         to X (not doing anything)
    #
    # This behaviour is a XOR gate on prev_value and actual_value
    #
    # This is done using a loop insted of NumPy vectorization bc it is a
    # recursive operation, cannot be vectorized

    for i in range(1, len(events)):
        events[i, 1] = events[i, 1] ^ events[i-1, 1]

    # Return np array
    return events


def slice_power_data(power_x_data, power_y_data, start_index, end_index):
    """ Slices the power data between given indexes, processing the time to
        be relative to 0
    """

    # Get the time slice and apply an offset (relative to start)
    time_slice = power_x_data[start_index:end_index+1]
    time_slice = time_slice - time_slice[0]

    # Get the power values slice
    power_slice = power_y_data[start_index:end_index+1]

    return time_slice, power_slice


def slice_traces_data(traces_x_data, traces_y_data, start_time, end_time):
    """ Slices the traces data between given time window, processing the time
        to be relative to 0
    """

    # Create a copá»³ of the list of lists
    local_traces_x_list = deepcopy(traces_x_data)
    local_traces_y_list = deepcopy(traces_y_data)

    return_traces_x_list = []
    return_traces_y_list = []

    # Generate the traces for the instants "start_time" and "end_time
    for traces_x_list, traces_y_list in zip(local_traces_x_list,
                                            local_traces_y_list):

        # Start

        # Get the index of the closest time below start_time
        prev_value_time_index = get_closest_element_below(traces_x_list,
                                                          start_time)

        # Get the time and signal value for that moment
        prev_time = traces_x_list[prev_value_time_index]
        prev_val = traces_y_list[prev_value_time_index]

        # If the prev_time is not start_time, it means there is no value
        # registered for the start_time instant.
        # That means that the value for the instant "start_time" is the same as
        # the one for the prev_instant.
        # So we insert the prev_instant value as the start_value and the
        # start_time as the timestamp
        #
        # WE INSERT IT IN THE INDEX RIGHT AFTER THE PREV_VALUE_INDEX SINCE
        # THE PREV_VALUE_TIME IS BEFORE THE START_TIME
        if prev_time != start_time:
            start_index = prev_value_time_index + 1
            traces_x_list = np.insert(traces_x_list, start_index, start_time)
            traces_y_list = np.insert(traces_y_list, start_index, prev_val)
        else:
            # If the prev_time equals the start_time it means the start_time
            # instant is registered, so we assign the prev_value_index to the
            # start_index
            start_index = prev_value_time_index

        # End

        # Get the closest element below end_time
            # The closes_element_below could be either the end_time index
            # (in case the end_time instant is registered)
            # or the closes event before end_time
            # In both cases, that is the instant we want to end the slice with
        end_index = get_closest_element_below(traces_x_list, end_time)

        # Generate the returned lists

        # Apply an offset to the time slice
        processed_traces_x_list = \
            traces_x_list[start_index:end_index+1] - traces_x_list[start_index]

        # Append x and y values for this sublist to the return list
        return_traces_x_list.append(processed_traces_x_list)
        return_traces_y_list.append(traces_y_list[start_index:end_index+1])

    return return_traces_x_list, return_traces_y_list


def process_monitor_data(power_buffer,
                        traces_buffer,
                        system_freq_MHz,
                        num_signals,
                        board,
                        filtering=False):
    """ Rebuild the event-based traces signals """

    # Path to the input files
    # power_path = input_path + "/CON" + input_id + ".BIN"
    # traces_path = input_path + "/SIG" + input_id + ".BIN"

    # POWER

    # Read power data
    if board == "ZCU":
        top_power_data, \
            bottom_power_data, \
            power_time = read_power_data(power_buffer, "ZCU")

        # Filter power data
        top_power_data = filter_power_data(top_power_data,
                                        filtering,
                                        16,
                                        1000000,
                                        100000)
        bottom_power_data = filter_power_data(bottom_power_data,
                                            filtering,
                                            16,
                                            1000000,
                                            100000)

        # Convert to x and y (watts) values
        power_values = process_power_values_zcu(top_power_data,
                                                bottom_power_data,
                                                power_time,
                                                system_freq_MHz,
                                                0,
                                                1)
    elif board == "PYNQ":
        # Read power data
        power_data, \
            power_time = read_power_data(power_buffer, "PYNQ")

        # Filter power data
        power_data = filter_power_data(power_data,
                                    filtering,
                                    16,
                                    1000000,
                                    100000)

        # Convert to x and y (watts) values
        power_values = process_power_values_pynq(power_data,
                                                power_time,
                                                system_freq_MHz)
    elif board == "AU250":
        # TODO: Implement this
        raise ValueError(f"Board not supported: {board}")
    else:
        raise ValueError(f"Board not supported: {board}")

    # Traces

    # Read traces data
    events_data_raw = read_traces_data(traces_buffer)

    # Process traces data
    traces_data_list = []
    for pos in range(num_signals):
        traces_data_list.append(process_traces_data(events_data_raw, pos))

    # Unpack traces
    traces_x_values_list = []
    traces_y_values_list = []
    # Convert from cycles to ms
    conversion_factor = system_freq_MHz * 1000  # (1 / conversion_factor) to convert from cycles to ms
    for array in traces_data_list:
        traces_x_values_list.append(array[:, 0] / conversion_factor)
        traces_y_values_list.append(np.copy(array[:, 1]))

    return power_values, \
        traces_x_values_list, \
        traces_y_values_list


def fragmentate_monitor_measurements_zcu(power_buffer,
                                            traces_buffer,
                                            kernel_combinations):
    """
    Fragmentates the monitor data to get the info
    corresponding just to each particular kernel combination (slicing the
    CON.BIN and SIG.BIN files)
    """

    # TODO: Make it customizable
    system_freq_MHz = 100
    num_signals = 16

    # Process the monitor data (dual)
    [top_power_x_values,\
        top_power_y_values,\
        bottom_power_x_values,\
        bottom_power_y_values],\
        traces_x_values_list,\
        traces_y_values_list = process_monitor_data(power_buffer,
                                                    traces_buffer,
                                                    system_freq_MHz,
                                                    num_signals,
                                                    board="ZCU",
                                                    filtering=False)

    # Generate the list of lists that will cointaint the sliced power and
    # traces data of each kernel configuration
    top_power_x_values_fragments_list = []
    top_power_y_values_fragments_list = []
    bottom_power_x_values_fragments_list = []
    bottom_power_y_values_fragments_list = []
    traces_x_values_fragments_list = []
    traces_y_values_fragments_list = []

    # For each kernel combination generate the slice power and traces data
    # and append them to a list of lists to be returned later
    for kernel_combination in kernel_combinations:

        # Store the start and end time for the kernel combination
        kernel_combination_window_start_time = kernel_combination[0]
        kernel_combination_window_end_time = kernel_combination[1]

        # Get the index of the closest_element_below the start and end time
        power_start_pos = \
            get_closest_element_below(top_power_x_values,
                                      kernel_combination_window_start_time)
        power_end_pos = \
            get_closest_element_below(top_power_x_values,
                                      kernel_combination_window_end_time)

        # Slice the top power data between the start and stop position
        new_top_power_x_values, \
            new_top_power_y_values = slice_power_data(top_power_x_values,
                                                    top_power_y_values,
                                                    power_start_pos,
                                                    power_end_pos)

        # Slice the bottom power data between the start and stop position
        new_bottom_power_x_values, \
            new_bottom_power_y_values = \
            slice_power_data(bottom_power_x_values,
                            bottom_power_y_values,
                            power_start_pos,
                            power_end_pos)

        # Slice the traces data between the start and stop times
        new_traces_x_values_list, \
            new_traces_y_values_list = \
            slice_traces_data(traces_x_values_list,
                            traces_y_values_list,
                            top_power_x_values[power_start_pos],
                            top_power_x_values[power_end_pos])

        # Append sliced data to a list of lists in the corresponding sublist
        top_power_x_values_fragments_list.append(new_top_power_x_values)
        top_power_y_values_fragments_list.append(new_top_power_y_values)
        bottom_power_x_values_fragments_list.append(new_bottom_power_x_values)
        bottom_power_y_values_fragments_list.append(new_bottom_power_y_values)
        traces_x_values_fragments_list.append(new_traces_x_values_list)
        traces_y_values_fragments_list.append(new_traces_y_values_list)

    # Return monitor measurement fragments
    return [[top_power_x_values_fragments_list,\
        top_power_y_values_fragments_list,\
        bottom_power_x_values_fragments_list,\
        bottom_power_y_values_fragments_list],\
        traces_x_values_fragments_list,\
        traces_y_values_fragments_list]


def fragmentate_monitor_measurements_pynq(power_buffer,
                                        traces_buffer,
                                        kernel_combinations):
    """
    Fragmentates the monitor data to get the info
    corresponding just to each particular kernel combination (slicing the
    CON.BIN and SIG.BIN files)
    """

    # TODO: Make it customizable
    system_freq_MHz = 100
    num_signals = 8

    # Process the monitor data (mono)
    [power_x_values,\
        power_y_values],\
        traces_x_values_list,\
        traces_y_values_list = process_monitor_data(power_buffer,
                                                    traces_buffer,
                                                    system_freq_MHz,
                                                    num_signals,
                                                    board="PYNQ",
                                                    filtering=False)

    # Generate the list of lists that will cointaint the sliced power and
    # traces data of each kernel configuration
    power_x_values_fragments_list = []
    power_y_values_fragments_list = []
    traces_power_x_values_fragments_list = []
    traces_power_y_values_fragments_list = []

    # For each kernel combination generate the slice power and traces data
    # and append them to a list of lists to be returned later
    for kernel_combination in kernel_combinations:

        # Store the start and end time for the kernel combination
        kernel_combination_window_start_time = kernel_combination[0]
        kernel_combination_window_end_time = kernel_combination[1]

        # Get the index of the closest_element_below the start and end time
        power_start_pos = \
            get_closest_element_below(power_x_values,
                                      kernel_combination_window_start_time)
        power_end_pos = \
            get_closest_element_below(power_x_values,
                                      kernel_combination_window_end_time)

        # Slice the top power data between the start and stop position
        new_power_x_values, \
            new_power_y_values = slice_power_data(power_x_values,
                                                power_y_values,
                                                power_start_pos,
                                                power_end_pos)

        # Slice the traces data between the start and stop times
        new_traces_x_values_list, \
            new_traces_y_values_list = \
            slice_traces_data(traces_x_values_list,
                            traces_y_values_list,
                            power_x_values[power_start_pos],
                            power_x_values[power_end_pos])

        # Append sliced data to a list of lists in the corresponding sublist
        power_x_values_fragments_list.append(new_power_x_values)
        power_y_values_fragments_list.append(new_power_y_values)
        traces_power_x_values_fragments_list.append(new_traces_x_values_list)
        traces_power_y_values_fragments_list.append(new_traces_y_values_list)

    # Return monitor measurement fragments
    return [[power_x_values_fragments_list,\
        power_y_values_fragments_list],\
        traces_power_x_values_fragments_list,\
        traces_power_y_values_fragments_list]


# Map board to functions
fragmentate_monitor_functions = {
    "ZCU": fragmentate_monitor_measurements_zcu,
    "PYNQ": fragmentate_monitor_measurements_pynq,
    # TODO: Implement AU250
}


def fragmentate_monitor_measurements(power_buffer,
                                    traces_buffer,
                                    kernel_combinations,
                                    board):
    """
    Fragmentates the monitor data to get the info
    corresponding just to each particular kernel combination (slicing the
    CON.BIN and SIG.BIN files)
    """

    if board not in fragmentate_monitor_functions:
        raise ValueError(f"Board not supported: {board}")

    return fragmentate_monitor_functions[board](power_buffer,
                                                traces_buffer,
                                                kernel_combinations)
